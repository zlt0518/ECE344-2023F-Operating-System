Lab 5

Assignment description
For all of your performance numbers, pick a value of -t based on the number of cores on your machine. You need to run this 
on a machine with at least 4 cores. If your machine does not, you can run it on the UG machines. After picking -t choose 
a value of -s such that the base hash table completes between 1-2 seconds. For all your performance runs ensure that -t times -s 
is always the same value (so that your program is always doing the same amount of work).

Q1 (15 points) Describe your first implementation strategy here (the one with a single mutex). 
Argue why your strategy is correct and contains no data races.

The first implementation is by modifying the data structure for each hashtable, and the lock used in the add_entry part
and the start and end. It allows every time only one entry could be added to any of one hash table by only one thread, 
which could effectively ensure the correctness of the code with no data race.



Q2 (15 points)Run the tester such that the base hash table completes in 1-2 seconds. 
Report the relative speedup (or slow down) compared to the base serial implementation with a low number of threads (-t 2) 
and a high number of threads (matching the number of cores on your machine). Note that the amount of work (-t times -s) 
should remain constant for both runs. Explain any differences between the two.

Running command for 2 threads:  build/pht-tester -t 2 -s 50000
Output:
Generation: 13741 usec
Hash table base: 30545 usec
  - 0 missing
Hash table v1: 63956 usec
  - 0 missing
Hash table v2: 18925 usec
  - 0 missing

Running command for 8 threads: build/pht-tester -t 8 -s 50000
Output:
Generation: 56884 usec
Hash table base: 658031 usec
  - 0 missing
Hash table v1: 5054562 usec
  - 0 missing
Hash table v2: 212584 usec
  - 0 missing

As shown above, the v1 hash table performs worse in both 2-thread cases and 8-thread cases compared to the base hash table. 
The slowdown is primarily due to the fact that the implementation only allows one thread to access the "critical region" and 
add an entry to the hash table.
As shown in the two tests with 2 threads and 8 threads, the execution time ratio between v1 and base case in 2 threads is 
63956/30545 = 2.093 compared to the 8 thread cases  5054562/658031 = 7.68, which indicates that the v1 gets even slower with more
threads create more overhead in using the mutex lock(lock/unlock process)


Q3 (15 points)Describe your second implementation strategy here (the one with a multiple mutexes). Argue why your strategy is correct.

The second implementation is by modifying the data structure for each entry of the hashtable, I added a mutex lock for each entry and 
multiple threads can access the hash table at the same time, while for each entry only one thread could access it. The parallelism is 
reflected in that they are allowed to access different entries at the same time The lock is initialized during the time of creating each 
entry of the hashtable in hash_table_v2_create and destroys it for each entry in hash_table_v2_destory.



Q4 (15 points)Run the tester such that the base hash table completes in 1-2 seconds. Report the relative speedup compared to the
base serial implementation with -t matching the number of cores on your machine (at least 4). Note again that the amount of work 
(-t times -s) should remain constant. Explain the difference between this implementation and your first, specifically why you get 
a performance increase.

Running command for 2 threads:  build/pht-tester -t 2 -s 50000
Output:
Generation: 13741 usec
Hash table base: 30545 usec
  - 0 missing
Hash table v1: 63956 usec
  - 0 missing
Hash table v2: 18925 usec
  - 0 missing

Running command for 8 threads: build/pht-tester -t 8 -s 50000
Output:
Generation: 56884 usec
Hash table base: 658031 usec
  - 0 missing
Hash table v1: 5054562 usec
  - 0 missing
Hash table v2: 212584 usec
  - 0 missing

As shown above, the v2 hash table performs better in both 2-thread cases and 8-thread cases compared to the v1 hash table.  
The speedup is primarily due to the fact that the implementation allows multiple threads to access the hash table at the 
same time and make each entry be critical region(smaller than before).
As shown in the two tests with 2 threads and 8 threads, the execution time ratio between v1 and v2 hashtable in 2 threads 
is 63956/18925 = 3.379 compared to the 8 thread cases  5054562/212584 = 23.776, which indicates that the v2 gets faster by
allowing parallelism and the increase in the performance is close to a linear increase where 23.776/3.379 = 7.036 close to 8
